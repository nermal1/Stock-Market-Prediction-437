{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53970970-5ccb-4e3f-9271-3c986514c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1be488-08d5-4fe3-b65a-eeb8ea1fff79",
   "metadata": {},
   "source": [
    "## Create features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011ef2c-9ea3-4aca-9143-00799764c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_data_features(df):\n",
    "    indicators = pd.DataFrame(index=df.index)\n",
    "\n",
    "    close = df[\"Close\"]\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    vol = df[\"Volume\"]\n",
    "\n",
    "    # Simple Moving Average 10 day\n",
    "    indicators[\"SMA10\"] = close.rolling(window=10).mean()\n",
    "\n",
    "    # Weighted Moving Average 10 day\n",
    "    weights = np.arange(1, 11)\n",
    "    indicators[\"WMA10\"] = close.rolling(10).apply(lambda x: np.dot(x, weights)/weights.sum(), raw=True)\n",
    "\n",
    "    # Momentum 10 day\n",
    "    indicators[\"MOM10\"] = close - close.shift(10)\n",
    "\n",
    "    # Stochastic Oscillator %K 14 day\n",
    "    indicators[\"STOCHK\"] = 100 * (close - low.rolling(14).min()) / (high.rolling(14).max() - low.rolling(14).min())\n",
    "\n",
    "    # Stochastic Oscillator %D 3 day SMA of %K\n",
    "    indicators[\"STOCHD\"] = indicators[\"STOCHK\"].rolling(3).mean()\n",
    "\n",
    "    # Relative Strength Index 14 day \n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -1 * delta.clip(upper=0)\n",
    "    rs = up.rolling(14).mean() / down.rolling(14).mean()\n",
    "    indicators[\"RSI14\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD 12-day EMA - 26 day EMA\n",
    "    ema12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema26 = close.ewm(span=26, adjust=False).mean()\n",
    "    indicators[\"MACD\"] = ema12 - ema26\n",
    "\n",
    "    # Williams %R 14 day\n",
    "    highest14 = high.rolling(14).max()\n",
    "    lowest14 = low.rolling(14).min()\n",
    "    indicators[\"WILLR\"] = -100 * (highest14 - close) / (highest14 - lowest14)\n",
    "\n",
    "    # 9. Accumulation/Distribution Oscillator (ADOSC)\n",
    "    clv = np.where((high - low) == 0, 0, ((close - low) - (high - close)) / (high - low))\n",
    "    adl = (clv * vol).cumsum()\n",
    "\n",
    "    ema3_adl = adl.ewm(span=3, adjust=False).mean()\n",
    "    ema10_adl = adl.ewm(span=10, adjust=False).mean()\n",
    "\n",
    "    adosc = ema3_adl - ema10_adl\n",
    "\n",
    "    # Scale ADOSC to 0–100 like in papers\n",
    "    min_val = adosc.min()\n",
    "    max_val = adosc.max()\n",
    "    indicators[\"ADOSC\"] = 100 * (adosc - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "    # 10. Commodity Channel Index 20 day\n",
    "    tp = (high + low + close) / 3\n",
    "    sma = tp.rolling(20).mean()\n",
    "    mad = (tp - sma).abs().rolling(20).mean()\n",
    "    indicators[\"CCI20\"] = (tp - sma) / (0.015 * mad)\n",
    "\n",
    "    indicators[\"Close\"] = close\n",
    "\n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f87b9-334f-484b-95ab-6a4d4ac3873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_deterministic_data(indicators, df):\n",
    "    trend = pd.DataFrame(index=indicators.index)\n",
    "\n",
    "    close = indicators[\"Close\"]\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    vol = df[\"Volume\"]\n",
    "\n",
    "    #SMA\n",
    "    trend[\"SMA10_T\"] = np.where(close > indicators[\"SMA10\"], 1, -1)\n",
    "\n",
    "    #WMA\n",
    "    trend[\"WMA10_T\"] = np.where(close > indicators[\"WMA10\"], 1, -1)\n",
    "\n",
    "    #Momentum\n",
    "    trend[\"MOM10_T\"] = np.where(indicators[\"MOM10\"] > 0, 1, -1)\n",
    "\n",
    "    # Sophisticated Oscillator trends\n",
    "    trend[\"STOCHK_T\"] = np.where(indicators[\"STOCHK\"] > indicators[\"STOCHK\"].shift(1), 1, -1)\n",
    "    trend[\"STOCHD_T\"] = np.where(indicators[\"STOCHD\"] > indicators[\"STOCHD\"].shift(1), 1, -1)\n",
    "\n",
    "    #RSI trend\n",
    "    rsi = indicators[\"RSI14\"]\n",
    "    trend[\"RSI14_T\"] = np.select([rsi > 70, rsi < 30, rsi > rsi.shift(1)],\n",
    "                                 [-1, 1, 1], default=-1)\n",
    "    #MACD trend\n",
    "    trend[\"MACD_T\"] = np.where(indicators[\"MACD\"] > indicators[\"MACD\"].shift(1), 1, -1)\n",
    "\n",
    "    #Williams %R trend\n",
    "    trend[\"WILLR_T\"] = np.where(indicators[\"WILLR\"] > indicators[\"WILLR\"].shift(1), 1, -1)\n",
    "\n",
    "    #ADOSC trend\n",
    "    trend[\"ADOSC_T\"] = np.where(indicators[\"ADOSC\"] > indicators[\"ADOSC\"].shift(1), 1, -1)\n",
    "\n",
    "    #CCI trend\n",
    "    cci = indicators[\"CCI20\"]\n",
    "    trend[\"CCI20_T\"] = np.select([cci > 200, cci < -200, cci > cci.shift(1)],\n",
    "                                 [-1, 1, 1], default=-1)\n",
    "    return trend\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb11afc-431d-49e5-85e0-7efe4df3120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"MSFT\", \"AMZN\", \"^GSPC\", \"^DJI\"]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ef50c-ccbd-4267-98ef-94efe0e82ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_neurons):\n",
    "        super(StockANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_neurons)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_neurons, 1)\n",
    "        self.output_act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.output_act(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb108e5-bd8a-4004-8eb1-329510a3d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_ann_pytorch(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32)\n",
    "    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X_train_t, y_train_t)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    hidden_neurons = [10, 20, 50, 100]\n",
    "    epochs_list = [1000, 2000, 5000]\n",
    "    momentum_values = [0.1, 0.3, 0.5, 0.9]\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in hidden_neurons:\n",
    "        for ep in epochs_list:\n",
    "            for mc in momentum_values:\n",
    "                model = StockANN(X_train.shape[1], n)\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=mc)\n",
    "\n",
    "                for epoch in range(ep):\n",
    "                    for inputs, labels in loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    preds = model(X_test_t).flatten()\n",
    "                    preds = torch.where(preds > 0, 1, -1).numpy()\n",
    "                    acc = accuracy_score(y_test, preds)\n",
    "                    f1 = f1_score(y_test, preds)\n",
    "\n",
    "                results.append({\n",
    "                    'Hidden Neurons': n,\n",
    "                    'Epochs': ep,\n",
    "                    'Momentum': mc,\n",
    "                    'Accuracy': acc,\n",
    "                    'F1': f1\n",
    "                })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    best = df_results.loc[df_results['Accuracy'].idxmax()]\n",
    "    print(\"✅ Best Continuous ANN Parameters:\")\n",
    "    print(best)\n",
    "    return df_results, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29f178-8324-4521-962a-d8c9eebd1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_ann_pytorch(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32)\n",
    "    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X_train_t, y_train_t)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    hidden_neurons = [10, 20, 50, 100]\n",
    "    epochs_list = [1000, 2000, 5000]\n",
    "    momentum_values = [0.1, 0.3, 0.5, 0.9]\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in hidden_neurons:\n",
    "        for ep in epochs_list:\n",
    "            for mc in momentum_values:\n",
    "                model = StockANN(X_train.shape[1], n)\n",
    "                criterion = nn.BCELoss()  # Binary classification\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=mc)\n",
    "\n",
    "                for epoch in range(ep):\n",
    "                    for inputs, labels in loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion((outputs + 1)/2, (labels + 1)/2)  # convert -1,1 -> 0,1\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    preds = model(X_test_t).flatten()\n",
    "                    preds = torch.where(preds > 0, 1, -1).numpy()\n",
    "                    acc = accuracy_score(y_test, preds)\n",
    "                    f1 = f1_score(y_test, preds)\n",
    "\n",
    "                results.append({\n",
    "                    'Hidden Neurons': n,\n",
    "                    'Epochs': ep,\n",
    "                    'Momentum': mc,\n",
    "                    'Accuracy': acc,\n",
    "                    'F1': f1\n",
    "                })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    best = df_results.loc[df_results['Accuracy'].idxmax()]\n",
    "    print(\"✅ Best Trend ANN Parameters:\")\n",
    "    print(best)\n",
    "    return df_results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde239a8-9074-469a-a8a3-a6e6d6d1aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    print(f\"Processing {ticker}\")\n",
    "    \n",
    "    df = yf.download(ticker, start=\"2015-01-01\", end=\"2024-12-31\", auto_adjust=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Target\"] = np.where(df[\"Close\"] > df[\"Close\"].shift(1), 1, -1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    y = df[\"Target\"]\n",
    "    X_cont_full = continuous_data_features(df)\n",
    "    X_cont = X_cont_full.drop(columns=[\"Close\"])\n",
    "\n",
    "    cont_aligned = pd.concat([X_cont, y], axis=1)\n",
    "    cont_aligned.dropna(inplace=True)\n",
    "    X_cont_clean = cont_aligned.drop(columns=['Target'])\n",
    "    y_cont_clean = cont_aligned['Target']\n",
    "\n",
    "    summary_results, _, _ = continuous_ann_pytorch(X_cont_clean, y_cont_clean)\n",
    "    print(\"\\n--- Continuous ANN Results ---\")\n",
    "    print(summary_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3095640-b6fb-44ef-be71-69e6c3bbfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    print(f\"Processing {ticker}\")\n",
    "    \n",
    "    df = yf.download(ticker, start=\"2015-01-01\", end=\"2024-12-31\", auto_adjust=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Target\"] = np.where(df[\"Close\"] > df[\"Close\"].shift(1), 1, -1)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    y = df[\"Target\"]\n",
    "    \n",
    "    X_cont_full = continuous_data_features(df)\n",
    "    X_trend_full = trend_deterministic_data(X_cont_full, df)\n",
    "\n",
    "    trend_aligned = pd.concat([X_trend_full, y], axis=1)\n",
    "    trend_aligned.dropna(inplace=True)\n",
    "    X_trend_clean = trend_aligned.drop(columns=['Target'])\n",
    "    y_trend_clean = trend_aligned['Target']\n",
    "\n",
    "    summary_results, _, _ = trend_ann_pytorch(X_trend_clean, y_trend_clean)\n",
    "    \n",
    "    print(\"\\n--- Trend ANN Results ---\")\n",
    "    print(summary_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f11664-4126-45f3-9f88-3c0bb7a9d27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
