{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a04019-1355-4bd0-8d0c-075fc70d515f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43743c7f-327f-4d34-aab2-81a206a0e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a153e2-0a33-4c1b-9c59-10ce7addb162",
   "metadata": {},
   "source": [
    "# Download Stocks/Indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354a1052-3d6f-48f9-ba07-81dd7a4e69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"MSFT\", \"AMZN\", \"^GSPC\", \"^DJI\"]\n",
    "data = yf.download(tickers, start=\"2003-01-01\", end=\"2012-01-01\", auto_adjust=False)\n",
    "ohlcv = {t: data.xs(t, axis=1, level=1) for t in tickers}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867ba02-1800-43a1-ac39-705af2d68ef2",
   "metadata": {},
   "source": [
    "# Create Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef1a9b9-3e40-4659-aeae-4c9137d02459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indicators(df):\n",
    "    indicators = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    close = df[\"Adj Close\"]\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    vol = df[\"Volume\"]\n",
    "    \n",
    "    # Simple Moving Average (10-day)\n",
    "    indicators[\"SMA10\"] = close.rolling(window=10).mean()\n",
    "    \n",
    "    # Weighted Moving Average (10-day)\n",
    "    weights = np.arange(1, 11)\n",
    "    indicators[\"WMA10\"] = close.rolling(10).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True)\n",
    "    \n",
    "    # Momentum (10-day)\n",
    "    indicators[\"MOM10\"] = close - close.shift(9)\n",
    "    \n",
    "    # Stochastic %K (14-day)\n",
    "    lowest_low = low.rolling(14).min()\n",
    "    highest_high = high.rolling(14).max()\n",
    "    indicators[\"STOCHK\"] = 100 * (close - lowest_low) / (highest_high - lowest_low)\n",
    "    \n",
    "    # Stochastic %D (3-day SMA of %K)\n",
    "    indicators[\"STOCHD\"] = indicators[\"STOCHK\"].rolling(3).mean()\n",
    "    \n",
    "    # Relative Strength Index (14-day)\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0).rolling(14).mean()\n",
    "    down = -delta.clip(upper=0).rolling(14).mean()\n",
    "    rs = up / down\n",
    "    indicators[\"RSI14\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD (12-26 EMA difference)\n",
    "    ema12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema26 = close.ewm(span=26, adjust=False).mean()\n",
    "    indicators[\"MACD\"] = ema12 - ema26\n",
    "    \n",
    "    # Williams %R (14-day)\n",
    "    indicators[\"WILLR\"] = -100 * (highest_high - close) / (highest_high - lowest_low)\n",
    "    \n",
    "    # Accumulation/Distribution Oscillator\n",
    "    clv = ((close - low) - (high - close)) / (high - low)\n",
    "    clv = clv.fillna(0) \n",
    "    indicators[\"ADOSC\"] = (clv * vol).cumsum()\n",
    "    \n",
    "    # Commodity Channel Index (20-day)\n",
    "    tp = (high + low + close) / 3\n",
    "    sma_tp = tp.rolling(20).mean()\n",
    "    mad = (tp - sma_tp).abs().rolling(20).mean()\n",
    "    indicators[\"CCI20\"] = (tp - sma_tp) / (0.015 * mad)\n",
    "    \n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c251cc1d-ee85-438f-a38c-69ef6752e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trend_deterministic(indicators, prices):\n",
    "    #computes trend deterministic data \n",
    "    trends = pd.DataFrame(index=indicators.index)\n",
    "    \n",
    "    # 1. SMA: +1 if price > SMA, -1 otherwise\n",
    "    trends['SMA10'] = np.where(prices > indicators['SMA10'], 1, -1)\n",
    "    \n",
    "    # 2. WMA: +1 if price > WMA, -1 otherwise\n",
    "    trends['WMA10'] = np.where(prices > indicators['WMA10'], 1, -1)\n",
    "    \n",
    "    # 3. Momentum: +1 if positive, -1 if negative\n",
    "    trends['MOM10'] = np.where(indicators['MOM10'] > 0, 1, -1)\n",
    "    \n",
    "    # 4. Stochastic %K: +1 if increasing, -1 if decreasing\n",
    "    trends['STOCHK'] = np.where(\n",
    "        indicators['STOCHK'] > indicators['STOCHK'].shift(1), 1, -1\n",
    "    )\n",
    "    \n",
    "    # 5. Stochastic %D: +1 if increasing, -1 if decreasing\n",
    "    trends['STOCHD'] = np.where(\n",
    "        indicators['STOCHD'] > indicators['STOCHD'].shift(1), 1, -1\n",
    "    )\n",
    "    \n",
    "    # 6. RSI: Special rules for overbought/oversold\n",
    "    rsi = indicators['RSI14']\n",
    "    rsi_trend = np.where(rsi > rsi.shift(1), 1, -1)\n",
    "    rsi_trend = np.where(rsi > 70, -1, rsi_trend)  # Overbought\n",
    "    rsi_trend = np.where(rsi < 30, 1, rsi_trend)   # Oversold\n",
    "    trends['RSI14'] = rsi_trend\n",
    "    \n",
    "    # 7. MACD: +1 if increasing, -1 if decreasing\n",
    "    trends['MACD'] = np.where(\n",
    "        indicators['MACD'] > indicators['MACD'].shift(1), 1, -1\n",
    "    )\n",
    "    \n",
    "    # 8. Williams %R: +1 if increasing, -1 if decreasing\n",
    "    trends['WILLR'] = np.where(\n",
    "        indicators['WILLR'] > indicators['WILLR'].shift(1), 1, -1\n",
    "    )\n",
    "    \n",
    "    # 9. A/D Oscillator: +1 if increasing, -1 if decreasing\n",
    "    trends['ADOSC'] = np.where(\n",
    "        indicators['ADOSC'] > indicators['ADOSC'].shift(1), 1, -1\n",
    "    )\n",
    "    \n",
    "    # 10. CCI: Special rules for overbought/oversold\n",
    "    cci = indicators['CCI20']\n",
    "    cci_trend = np.where(cci > cci.shift(1), 1, -1)\n",
    "    cci_trend = np.where(cci > 200, -1, cci_trend)   # Overbought\n",
    "    cci_trend = np.where(cci < -200, 1, cci_trend)   # Oversold\n",
    "    trends['CCI20'] = cci_trend\n",
    "    \n",
    "    return trends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "482cd983-645b-42f7-9d82-929baef2883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    \"\"\"Normalize continuous features to [-1, +1] range\"\"\"\n",
    "    X_train_norm = X_train.copy()\n",
    "    X_test_norm = X_test.copy()\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        min_val = X_train[col].min()\n",
    "        max_val = X_train[col].max()\n",
    "        \n",
    "        if max_val > min_val:  # Avoid division by zero\n",
    "            X_train_norm[col] = 2 * (X_train[col] - min_val) / (max_val - min_val) - 1\n",
    "            X_test_norm[col] = 2 * (X_test[col] - min_val) / (max_val - min_val) - 1\n",
    "    \n",
    "    return X_train_norm, X_test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da0ef8c-caef-4b58-abf3-aa29f40dd51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Statistics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'indicators_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add after computing trends, before training:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeature Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContinuous features - any NaN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindicators_final\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscrete features - any NaN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrends_final\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDiscrete feature value distribution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indicators_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Add after computing trends, before training:\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(f\"Continuous features - any NaN: {indicators_final.isna().any().any()}\")\n",
    "print(f\"Discrete features - any NaN: {trends_final.isna().any().any()}\")\n",
    "print(f\"\\nDiscrete feature value distribution:\")\n",
    "print((trends_final == 1).sum() / len(trends_final))  # Should be around 0.5\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"Train: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37b35d10-15f4-4283-905c-173d0075d22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing MSFT\n",
      "============================================================\n",
      "Dataset size: 2229 samples\n",
      "Target distribution - Up: 1108, Down: 1121\n",
      "\n",
      "--- Continuous Representation (GaussianNB) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m y_pred_cont \u001b[38;5;241m=\u001b[39m gnb\u001b[38;5;241m.\u001b[39mpredict(X_test_norm)\n\u001b[1;32m     60\u001b[0m acc_cont \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_cont)\n\u001b[0;32m---> 61\u001b[0m f1_cont \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred_cont, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_cont\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF-measure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_cont\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "results_summary = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {ticker}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    df = ohlcv[ticker].copy()\n",
    "    \n",
    "    # Compute continuous indicators\n",
    "    indicators = compute_indicators(df)\n",
    "    \n",
    "    # Create target: 1 if next day's price goes up, 0 otherwise\n",
    "    target = (df[\"Adj Close\"].shift(-1) > df[\"Adj Close\"]).astype(int)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_idx = indicators.dropna().index\n",
    "    indicators_clean = indicators.loc[valid_idx]\n",
    "    target_clean = target.loc[valid_idx]\n",
    "    prices_clean = df[\"Adj Close\"].loc[valid_idx]\n",
    "    \n",
    "    # Compute trend deterministic representation\n",
    "    trends = compute_trend_deterministic(indicators_clean, prices_clean)\n",
    "    trends_clean = trends.dropna()\n",
    "    \n",
    "    # Align all data\n",
    "    common_idx = trends_clean.index.intersection(target_clean.index)\n",
    "    indicators_final = indicators_clean.loc[common_idx]\n",
    "    trends_final = trends_clean.loc[common_idx]\n",
    "    target_final = target_clean.loc[common_idx]\n",
    "\n",
    "    print(f\"Dataset size: {len(common_idx)} samples\")\n",
    "    print(f\"Target distribution - Up: {target_final.sum()}, Down: {len(target_final) - target_final.sum()}\")\n",
    "\n",
    "\n",
    "    X_train_cont, X_test_cont, y_train, y_test, idx_train, idx_test = train_test_split(indicators_final, \n",
    "                                                                                       target_final, \n",
    "                                                                                       common_idx, \n",
    "                                                                                       test_size=0.2, \n",
    "                                                                                       shuffle=False,\n",
    "                                                                                        random_state=42)\n",
    "    # ============================================\n",
    "    # APPROACH 1: Continuous-valued Input (GaussianNB)\n",
    "    # ============================================\n",
    "    print(f\"\\n--- Continuous Representation (GaussianNB) ---\")\n",
    "    \n",
    "    X_train_cont = indicators_final.loc[idx_train]\n",
    "    X_test_cont = indicators_final.loc[idx_test]\n",
    "    y_train = target_final.loc[idx_train]\n",
    "    y_test = target_final.loc[idx_test]\n",
    "    \n",
    "    # Normalize to [-1, +1] as per paper\n",
    "    X_train_norm, X_test_norm = normalize_features(X_train_cont, X_test_cont)\n",
    "    \n",
    "    # Train GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train_norm, y_train)\n",
    "    y_pred_cont = gnb.predict(X_test_norm)\n",
    "    \n",
    "    acc_cont = accuracy_score(y_test, y_pred_cont)\n",
    "    f1_cont = f1_score(y_test, y_pred_cont, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {acc_cont:.4f}\")\n",
    "    print(f\"F-measure: {f1_cont:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_cont, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # ============================================\n",
    "    # APPROACH 2: Trend Deterministic Input (BernoulliNB)\n",
    "    # ============================================\n",
    "    print(f\"\\n--- Discrete Representation (BernoulliNB) ---\")\n",
    "    \n",
    "    X_train_disc = trends_final.loc[train_idx]\n",
    "    X_test_disc = trends_final.loc[test_idx]\n",
    "    \n",
    "    # Convert from {-1, +1} to {0, 1} for BernoulliNB\n",
    "    X_train_binary = ((X_train_disc + 1) / 2).astype(int)\n",
    "    X_test_binary = ((X_test_disc + 1) / 2).astype(int)\n",
    "    \n",
    "    # Train BernoulliNB\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train_binary, y_train)\n",
    "    y_pred_disc = bnb.predict(X_test_binary)\n",
    "    \n",
    "    acc_disc = accuracy_score(y_test, y_pred_disc)\n",
    "    f1_disc = f1_score(y_test, y_pred_disc, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {acc_disc:.4f}\")\n",
    "    print(f\"F-measure: {f1_disc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_disc, target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Store results\n",
    "    results_summary.append({\n",
    "        'Ticker': ticker,\n",
    "        'Continuous_Accuracy': acc_cont,\n",
    "        'Continuous_F1': f1_cont,\n",
    "        'Discrete_Accuracy': acc_disc,\n",
    "        'Discrete_F1': f1_disc,\n",
    "        'Improvement': acc_disc - acc_cont\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e916b7a1-c191-4293-bf20-9c597c93f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SUMMARY\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Continuous_Accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results_summary)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAverage Continuous Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContinuous_Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Discrete Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiscrete_Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Improvement: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImprovement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Continuous_Accuracy'"
     ]
    }
   ],
   "source": [
    "print(\"FINAL SUMMARY\")\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nAverage Continuous Accuracy: {results_df['Continuous_Accuracy'].mean():.4f}\")\n",
    "print(f\"Average Discrete Accuracy: {results_df['Discrete_Accuracy'].mean():.4f}\")\n",
    "print(f\"Average Improvement: {results_df['Improvement'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edb7a7-b1d2-4cd3-b739-2631e2dfb837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
